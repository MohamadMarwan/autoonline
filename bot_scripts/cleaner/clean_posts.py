# bot_scripts/cleaner/clean_posts.py

import os
import re
import time
import logging
import argparse
import sys
import json  # <-- âœ… Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù…ÙƒØªØ¨Ø© JSON
from bs4 import BeautifulSoup, NavigableString
from googleapiclient.discovery import build
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials

# --- Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø© ---
SCOPES = ['https://www.googleapis.com/auth/blogger']
LOG_FILE = 'edited_posts.log'
logging.basicConfig(filename=LOG_FILE, level=logging.INFO, format='%(asctime)s - %(message)s')

# âœ… ØªÙ… Ø­Ø°Ù CUSTOM_REMOVE_LIST Ù…Ù† Ù‡Ù†Ø§. Ø³ÙŠØªÙ… Ø§Ù„Ø¢Ù† Ù‚Ø±Ø§Ø¡ØªÙ‡Ø§ Ù…Ù† Ù…Ù„Ù.

def get_blogger_service(creds_path):
    # (Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø© ØªØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡ÙŠ)
    creds = None; token_file = os.path.join(creds_path, 'token.json'); secret_file = os.path.join(creds_path, 'client_secret.json')
    if os.path.exists(token_file): creds = Credentials.from_authorized_user_file(token_file, SCOPES)
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token: creds.refresh(Request())
        else:
            if not os.path.exists(secret_file):
                print(f"Ø®Ø·Ø£ ÙØ§Ø¯Ø­: Ù…Ù„Ù client_secret.json ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ: {secret_file}"); sys.exit(1)
            flow = InstalledAppFlow.from_client_secrets_file(secret_file, SCOPES)
            creds = flow.run_local_server(port=0)
        with open(token_file, 'w') as token: token.write(creds.to_json())
    return build('blogger', 'v3', credentials=creds)

# --- âœ… ØªÙ… ØªØ¹Ø¯ÙŠÙ„ Ø¯ÙˆØ§Ù„ Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ù„ØªÙ‚Ø¨Ù„ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ ÙƒÙ€ "ÙˆØ³ÙŠØ·" ---
def clean_title(title, rules):
    remove_symbols = rules.get('remove_symbols', [])
    title = re.sub(r'\s*\(.*?\)', '', title).strip()
    for symbol in remove_symbols:
        title = title.replace(symbol, '')
    return title

def extract_keywords(title):
    STOPWORDS = {"Ø¹Ø§Ø¬Ù„", "ØªÙØ§ØµÙŠÙ„", "Ø®Ø¨Ø±", "Ø§Ù„ÙŠÙˆÙ…", "ÙƒØ§Ù…Ù„", "ÙÙŠØ¯ÙŠÙˆ", "Ø´Ø§Ù‡Ø¯", "Ø¨Ø§Ù„ØµÙˆØ±", "Ø¨Ø§Ù„ÙÙŠØ¯ÙŠÙˆ", "Ø®Ø§Øµ"}
    words = re.findall(r'\w+', title)
    return ' '.join([w for w in words if w not in STOPWORDS and len(w) > 2][:6])

def add_smart_alt_to_images(soup, post_title):
    alt_text = extract_keywords(post_title)
    for img in soup.find_all("img"):
        if not img.get("alt"): img["alt"] = alt_text
        if not img.get("title"): img["title"] = alt_text
    return soup

def clean_content(content, post_title, rules):
    soup = BeautifulSoup(content, 'html.parser')
    soup = add_smart_alt_to_images(soup, post_title)
    
    # ... (Ø­Ø°Ù "ØªÙ… Ø§Ù„Ù†Ø´Ø± ÙÙŠ" Ùˆ ÙˆØ³ÙˆÙ… time/component ÙŠØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡Ùˆ) ...
    for el in soup.find_all(string=re.compile(r'ØªÙ… Ø§Ù„Ù†Ø´Ø± ÙÙŠ:')):
        if el.parent: el.extract()
    for time_tag in soup.find_all('time'): time_tag.decompose()
    for comp in soup.find_all('component'):
        if 'googletag.cmd.push' in str(comp): comp.decompose()

    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© Ù…Ù† Ø§Ù„Ù…Ù„Ù
    remove_symbols = rules.get('remove_symbols', [])
    replacements = rules.get('replacements', [])

    for text_node in soup.find_all(string=True):
        if isinstance(text_node, NavigableString):
            text_str = str(text_node)
            for rep in replacements:
                text_str = text_str.replace(rep.get('find', ''), rep.get('replace_with', ''))
            for symbol in remove_symbols:
                text_str = text_str.replace(symbol, '')
            if text_str != text_node:
                text_node.replace_with(text_str)
    return str(soup)

# âœ… ØªÙ… ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„ØªÙ‚Ø¨Ù„ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯
def clean_post_titles_and_content(blog_id, creds_path, limit, rules):
    service = get_blogger_service(creds_path)
    print(f"ğŸ”„ Ø¬Ø§Ø±ÙŠ Ø¬Ù„Ø¨ Ø¢Ø®Ø± {limit} Ù…Ù‚Ø§Ù„ Ù…Ù† Ø§Ù„Ù…Ø¯ÙˆÙ†Ø©: {blog_id}...")
    
    try:
        posts = service.posts().list(blogId=blog_id, maxResults=limit, fetchBodies=True).execute()
    except Exception as e:
        print(f"âŒ ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª: {e}"); sys.exit(1)

    for post in posts.get('items', []):
        original_title = post.get('title', '')
        original_content = post.get('content', '')
        if not original_title or not original_content: continue

        cleaned_title = clean_title(original_title, rules)
        cleaned_content = clean_content(original_content, original_title, rules)
        
        has_changed = (original_title != cleaned_title) or (original_content != cleaned_content)
        if has_changed:
            print(f"\nâœï¸ ØªØ¹Ø¯ÙŠÙ„ Ù…Ù‚Ø§Ù„: {original_title}")
            post_body = {'title': cleaned_title, 'content': cleaned_content}
            try:
                service.posts().patch(blogId=blog_id, postId=post['id'], body=post_body).execute()
                print(f"âœ… ØªÙ… ØªØ¹Ø¯ÙŠÙ„: {original_title}")
                time.sleep(1.5)
            except Exception as e:
                print(f"âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ù‚Ø§Ù„ '{original_title}': {e}")
        else:
            print(f"âœ… Ø¨Ø¯ÙˆÙ† ØªØ¹Ø¯ÙŠÙ„: {original_title}")

# âœ… --- ØªÙ… ØªØ¹Ø¯ÙŠÙ„ Ù†Ù‚Ø·Ø© Ø§Ù†Ø·Ù„Ø§Ù‚ Ø§Ù„Ø³ÙƒØ±Ø¨Øª Ù„Ù‚Ø¨ÙˆÙ„ Ù…Ù„Ù Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ ---
if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="Blogger Post Cleaner")
    parser.add_argument("--blog-id", type=str, required=True, help="ID of the Blogger blog.")
    parser.add_argument("--creds-path", type=str, required=True, help="Path to the credential directory.")
    parser.add_argument("--limit", type=int, default=12, help="Number of recent posts to clean.")
    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ÙˆØ³ÙŠØ· Ø§Ù„Ø¬Ø¯ÙŠØ¯
    parser.add_argument("--rules-file", type=str, required=True, help="Path to the JSON file with cleaning rules.")
    args = parser.parse_args()
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ù…Ù† Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø°ÙŠ ØªÙ… ØªÙ…Ø±ÙŠØ±Ù‡
    try:
        with open(args.rules_file, 'r', encoding='utf-8') as f:
            cleaning_rules = json.load(f)
    except Exception as e:
        print(f"âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±: {args.rules_file}. Ø§Ù„Ø®Ø·Ø£: {e}")
        sys.exit(1)
    
    print("--- Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª ---")
    # ØªÙ…Ø±ÙŠØ± Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªÙŠ ØªÙ… ØªØ­Ù…ÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
    clean_post_titles_and_content(args.blog_id, args.creds_path, args.limit, cleaning_rules)
    print("--- Ø§Ù†ØªÙ‡Øª Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªÙ†Ø¸ÙŠÙ ---")